import os
import numpy as np
import cv2
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
from flask import Flask, request, jsonify
import firebase_admin
from firebase_admin import credentials, firestore
import math
import gc 
import urllib.request # <--- M·ªöI: Th∆∞ vi·ªán ƒë·ªÉ t·∫£i ·∫£nh t·ª´ URL

# --- IMPORT CUSTOM MODULES ---
import facenet
import align.detect_face

app = Flask(__name__)

# ================= CONFIG =================
SERVICE_ACCOUNT_FILE = "./service-account.json"
FACENET_MODEL_PATH = './Models/20180402-114759.pb'
COLLECTION_FACES = "FaceEmbeddings" 
LOG_COLLECTION = "AccessLogs"       

DISTANCE_THRESHOLD = 1.0 

# ================= FIREBASE SETUP =================
db = None
try:
    cred = credentials.Certificate(SERVICE_ACCOUNT_FILE)
    firebase_admin.initialize_app(cred)
    db = firestore.client()
    print("‚úÖ Connected to Firebase Firestore")
except Exception as e:
    print("‚ùå Failed to connect to Firebase:", e)

# ================= AI MODEL LOADING =================
print("‚è≥ Loading Facenet Model...")
sess = tf.Session()
with sess.as_default():
    facenet.load_model(FACENET_MODEL_PATH)
    images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")
    embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")
    phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")
    
    # Load MTCNN
    pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)
print("üöÄ Server Ready!")

# ================= HELPER FUNCTIONS =================
def url_to_image(url):
    """M·ªöI: T·∫£i ·∫£nh t·ª´ URL v√† chuy·ªÉn th√†nh OpenCV Image"""
    try:
        resp = urllib.request.urlopen(url)
        image = np.asarray(bytearray(resp.read()), dtype="uint8")
        frame = cv2.imdecode(image, cv2.IMREAD_COLOR)
        return frame
    except Exception as e:
        print("L·ªói t·∫£i ·∫£nh t·ª´ URL:", e)
        return None

def get_embedding(frame):
    """H√†m tr√≠ch xu·∫•t vector ƒë·∫∑c tr∆∞ng"""
    global sess, pnet, rnet, onet
    
    # --- [ƒêO·∫†N CODE M·ªöI TH√äM V√ÄO] ---
    # M·ª•c ƒë√≠ch: Gi·∫£m k√≠ch th∆∞·ªõc ·∫£nh xu·ªëng d∆∞·ªõi 640px tr∆∞·ªõc khi ƒë∆∞a v√†o AI.
    # Vi·ªác n√†y gi√∫p gi·∫£m RAM t·ª´ 4GB xu·ªëng ch·ªâ c√≤n ~200MB, tr√°nh l·ªói s·∫≠p server.
    height, width = frame.shape[:2]
    max_dim = 640  # K√≠ch th∆∞·ªõc t·ªëi ƒëa cho ph√©p
    
    if width > max_dim or height > max_dim:
        # T√≠nh t·ªâ l·ªá thu nh·ªè
        scale = max_dim / max(width, height)
        new_width = int(width * scale)
        new_height = int(height * scale)
        # Th·ª±c hi·ªán resize
        frame = cv2.resize(frame, (new_width, new_height))
    # --- [H·∫æT ƒêO·∫†N CODE M·ªöI] ---
    
    # 1. Detect Face (ƒêo·∫°n n√†y gi·ªØ nguy√™n nh∆∞ c≈©)
    bounding_boxes, _ = align.detect_face.detect_face(frame, 20, pnet, rnet, onet, [0.65, 0.75, 0.75], 0.709)
    if bounding_boxes.shape[0] == 0:
        return None 
        
    # L·∫•y m·∫∑t to nh·∫•t
    det = bounding_boxes[:, 0:4]
    img_size = np.asarray(frame.shape)[0:2]
    
    bounding_box_size = (det[:, 2] - det[:, 0]) * (det[:, 3] - det[:, 1])
    img_center = img_size / 2
    offsets = np.vstack([ (det[:, 0] + det[:, 2]) / 2 - img_center[1], (det[:, 1] + det[:, 3]) / 2 - img_center[0] ])
    offset_dist_squared = np.sum(np.power(offsets, 2.0), 0)
    index = np.argmax(bounding_box_size - offset_dist_squared * 2.0) 
    
    bb = np.zeros(4, dtype=np.int32)
    bb[0] = np.maximum(det[index, 0], 0)
    bb[1] = np.maximum(det[index, 1], 0)
    bb[2] = np.minimum(det[index, 2], img_size[1])
    bb[3] = np.minimum(det[index, 3], img_size[0])
    
    cropped = frame[bb[1]:bb[3], bb[0]:bb[2], :]
    
    # 2. Preprocess & Embedding
    scaled = cv2.resize(cropped, (160, 160), interpolation=cv2.INTER_CUBIC)
    scaled = facenet.prewhiten(scaled)
    scaled_reshape = scaled.reshape(-1, 160, 160, 3)
    
    feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False}
    emb_array = sess.run(embeddings, feed_dict=feed_dict)
    
    return emb_array[0]
def load_known_faces():
    """T·∫£i to√†n b·ªô khu√¥n m·∫∑t ƒë√£ ƒëƒÉng k√Ω t·ª´ Firestore"""
    known_faces = []
    if db:
        docs = db.collection(COLLECTION_FACES).stream()
        for doc in docs:
            data = doc.to_dict()
            known_faces.append({
                "name": data["name"],
                "embedding": np.array(data["embedding"]) 
            })
    return known_faces

# ================= API 1: ƒêƒÇNG K√ù (H·ªó tr·ª£ c·∫£ File v√† URL) =================
@app.route('/register', methods=['POST'])
def register_face():
    frame = None
    name = None

    # C√°ch 1: G·ª≠i qua Link (Thunkable g·ª≠i JSON)
    if request.is_json:
        data = request.get_json()
        if 'url' in data:
            print("ƒêang t·∫£i ·∫£nh ƒëƒÉng k√Ω t·ª´ URL...")
            frame = url_to_image(data['url'])
        if 'name' in data:
            name = data['name']

    # C√°ch 2: G·ª≠i qua File tr·ª±c ti·∫øp
    elif 'file' in request.files:
        file = request.files['file']
        npimg = np.frombuffer(file.read(), np.uint8)
        frame = cv2.imdecode(npimg, cv2.IMREAD_COLOR)
        if 'name' in request.form:
            name = request.form['name']

    # Ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o
    if frame is None:
        return jsonify({"error": "Kh√¥ng nh·∫≠n ƒë∆∞·ª£c ·∫£nh (ho·∫∑c URL l·ªói)"}), 400
    if name is None:
        return jsonify({"error": "Thi·∫øu t√™n ng∆∞·ªùi d√πng"}), 400
    
    # X·ª≠ l√Ω AI
    emb = get_embedding(frame)
    
    # D·ªçn r√°c ngay
    del frame
    gc.collect()

    if emb is None:
        return jsonify({"error": "Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh"}), 400
        
    try:
        db.collection(COLLECTION_FACES).document(name).set({
            "name": name,
            "embedding": emb.tolist(),
            "created_at": firestore.SERVER_TIMESTAMP
        })
        return jsonify({"status": "success", "message": f"Registered {name}"})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# ================= API 2: NH·∫¨N DI·ªÜN (H·ªó tr·ª£ c·∫£ File v√† URL) =================
@app.route('/detect', methods=['POST'])
def detect_face():
    frame = None

    # C√°ch 1: G·ª≠i qua Link (Thunkable g·ª≠i JSON)
    if request.is_json and 'url' in request.json:
        print("ƒêang t·∫£i ·∫£nh nh·∫≠n di·ªán t·ª´ URL...")
        frame = url_to_image(request.json['url'])
    
    # C√°ch 2: G·ª≠i qua File
    elif 'file' in request.files:
        file = request.files['file']
        npimg = np.frombuffer(file.read(), np.uint8)
        frame = cv2.imdecode(npimg, cv2.IMREAD_COLOR)
    
    if frame is None:
        return jsonify({"error": "Kh√¥ng nh·∫≠n ƒë∆∞·ª£c ·∫£nh"}), 400
    
    # 1. L·∫•y vector c·ªßa m·∫∑t ng∆∞·ªùi ƒëang login
    target_emb = get_embedding(frame)
    
    # D·ªçn r√°c ·∫£nh ngay
    del frame
    gc.collect()

    if target_emb is None:
        return jsonify({"status": "no_face_found"}), 200
        
    # 2. T·∫£i danh s√°ch ng∆∞·ªùi ƒë√£ ƒëƒÉng k√Ω v·ªÅ
    known_faces = load_known_faces()
    if not known_faces:
         return jsonify({"status": "unknown", "message": "Database empty"}), 200
         
    # 3. So s√°nh kho·∫£ng c√°ch
    min_dist = 100.0
    identified_name = "Unknown"
    
    for face in known_faces:
        dist = np.sqrt(np.sum(np.square(target_emb - face["embedding"])))
        if dist < min_dist:
            min_dist = dist
            if dist < DISTANCE_THRESHOLD:
                identified_name = face["name"]
                
    # 4. Tr·∫£ k·∫øt qu·∫£
    result = {
        "name": identified_name,
        "distance": float(min_dist),
        "status": "success" if identified_name != "Unknown" else "unknown"
    }
    
    if identified_name != "Unknown":
         db.collection(LOG_COLLECTION).add({
             "name": identified_name,
             "timestamp": firestore.SERVER_TIMESTAMP
         })
         
    return jsonify(result)

if __name__ == "__main__":
    app.run(host='0.0.0.0', port=8080)